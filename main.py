import streamlit as st
import pandas as pd
# from streamlit_molstar import st_molstar, st_molstar_rcsb, st_molstar_remote
# å¦‚éœ€ä½¿ç”¨å£è¢‹é¢„æµ‹ç›¸å…³å‡½æ•°
from streamlit_molstar.pocket import (
    select_pocket_from_local_protein,
    # å¦‚æœä½ çš„é¡¹ç›®éœ€è¦ä¹Ÿå¯ä»¥ import select_pocket_from_upload_protein
)
# docking æ¨¡å—
from streamlit_molstar.docking import st_molstar_docking

import os
import json
import subprocess
import tempfile  # ç”¨äºåˆ›å»ºä¸´æ—¶æ–‡ä»¶
import re
# import tqdm

# å¦‚æœæ²¡æœ‰åœ¨ session_state ä¸­è®°å½• page,å°±åˆå§‹åŒ–ä¸€ä¸ªé»˜è®¤å€¼
if 'page' not in st.session_state:
    st.session_state['page'] = 'ä¸»é¡µ'

# åœ¨ä¾§è¾¹æ ä½¿ç”¨æŒ‰é’®æ¥åˆ‡æ¢é¡µé¢
st.sidebar.title("Navigation")
if st.sidebar.button("ä¸»é¡µ"):
    st.session_state['page'] = "ä¸»é¡µ"

# æ–°å¢â€œå‡†å¤‡é…ä½“â€æŒ‰é’®ï¼ˆæ’åœ¨â€œä¸»é¡µâ€å’Œâ€œå£è¢‹é¢„æµ‹â€ä¹‹é—´ï¼‰
if st.sidebar.button("å‡†å¤‡é…ä½“"):
    st.session_state['page'] = "å‡†å¤‡é…ä½“"

if st.sidebar.button("å£è¢‹é¢„æµ‹"):
    st.session_state['page'] = "å£è¢‹é¢„æµ‹"
if st.sidebar.button("åˆ†å­å¯¹æ¥"):
    st.session_state['page'] = "åˆ†å­å¯¹æ¥"
if st.sidebar.button("æ‰¹é‡å£è¢‹é¢„æµ‹ä¸å¯¹æ¥"):
    st.session_state['page'] = "æ‰¹é‡å£è¢‹é¢„æµ‹ä¸å¯¹æ¥"
    # æ–°å¢â€œé¢„æµ‹äº²å’ŒåŠ›â€æŒ‰é’®
if st.sidebar.button("é¢„æµ‹äº²å’ŒåŠ›"):
    st.session_state['page'] = "é¢„æµ‹äº²å’ŒåŠ›"
# æ–°å¢â€œä½œè€…ä¿¡æ¯â€æŒ‰é’®
if st.sidebar.button("ä½œè€…ä¿¡æ¯"):
    st.session_state['page'] = "ä½œè€…ä¿¡æ¯"

# è·å–å½“å‰é¡µé¢
page = st.session_state['page']

# ------------------------------------------------------------------------------
# ä¸»é¡µ
# ------------------------------------------------------------------------------
if page == "ä¸»é¡µ":
    # ä½¿ç”¨ HTML å’Œ Markdown å±…ä¸­æ ‡é¢˜
    st.markdown(
        "<h1 style='text-align: center;'>âš¡ï¸æ¬¢è¿ä½¿ç”¨âš¡ï¸</h1>",
        unsafe_allow_html=True,
    )
    st.markdown("<br>", unsafe_allow_html=True)

    # æ˜¾ç¤ºå­—ç¬¦ç”»
    try:
        with open("./lib/logo.txt", "r", encoding="utf-8") as file:
            ascii_art = file.read()
            styled_ascii_art = ascii_art.replace(" ", "&nbsp;").replace("\n", "<br>")
            html_code = f"""
            <div style='text-align: center; font-family: monospace; font-size: 14px; line-height: 1;'>
                {styled_ascii_art}
            </div>
            """
            st.markdown(html_code, unsafe_allow_html=True)

    except FileNotFoundError:
        st.error("logo.txt æ–‡ä»¶æœªæ‰¾åˆ°,è¯·ç¡®ä¿å®ƒä¸è„šæœ¬ä½äºåŒä¸€ç›®å½•ä¸‹")
    except UnicodeDecodeError:
        st.error("æ— æ³•è§£ç  logo.txt æ–‡ä»¶,è¯·ç¡®è®¤æ–‡ä»¶ç¼–ç æ ¼å¼æ˜¯å¦ä¸º UTF-8")

    # åœ¨å­—ç¬¦ç”»å’Œå›¾ç‰‡ä¹‹é—´æ’å…¥è‹¥å¹²ç©ºè¡Œ
    st.markdown("<br><br><br><br><br>", unsafe_allow_html=True)

    # æ˜¾ç¤º logo.png
    if os.path.exists("./lib/logo.png"):
        st.image("./lib/logo.png", use_container_width=True)
    else:
        st.error("logo.png æ–‡ä»¶æœªæ‰¾åˆ°,è¯·ç¡®ä¿å®ƒä½äº lib ç›®å½•ä¸‹")

# ------------------------------------------------------------------------------
# å‡†å¤‡é…ä½“
# ------------------------------------------------------------------------------
elif page == "å‡†å¤‡é…ä½“":
    st.title("å‡†å¤‡é…ä½“")

    import os
    from rdkit import Chem
    from rdkit.Chem import AllChem, Draw
    import py3Dmol
    from stmol import showmol
    from streamlit_ketcher import st_ketcher

    # 1. å…è®¸ç”¨æˆ·ä¸Šä¼ ä¸€ä¸ª SDF æ–‡ä»¶
    st.info("è¯·ä¸Šä¼ ä¸€ä¸ª SDF æ–‡ä»¶,æˆ–åœ¨ç”»å¸ƒä¸­ç»˜åˆ¶åˆ†å­ç»“æ„/ç²˜è´´SMILES")
    st.markdown("**ä¸Šä¼ **åˆ†å­æ–‡ä»¶ (SDF æ ¼å¼): ")
    sdf_file = st.file_uploader("", type=["sdf"])
    # 2. å…è®¸ç”¨æˆ·ä½¿ç”¨ Ketcher ç»˜åˆ¶æˆ–è¾“å…¥ SMILES
    st.markdown("**æˆ–è€…** åœ¨ä¸‹æ–¹ç»˜åˆ¶åˆ†å­ç»“æ„/ç²˜è´´SMILES: ")
    smiles_input = st_ketcher()

    def process_and_show_mol(
        mol: Chem.Mol, 
        uploaded_sdf_name: str = None, 
        user_defined_filename: str = None
    ):
        """
        å¯¹åˆ†å­è¿›è¡ŒåŠ æ°¢ã€3D åµŒå…¥ã€MMFF ä¼˜åŒ–å¹¶å±•ç¤º 2D/3D ç»“æ„ï¼›
        æ ¹æ®ä¸åŒæ¥æºå†³å®šæœ€ç»ˆä¿å­˜çš„æ–‡ä»¶åï¼š
        - å¦‚æœæœ‰ uploaded_sdf_name, åˆ™ç”¨ "åŸæ–‡ä»¶åå»é™¤.sdf + '_prepared.sdf'"
        - å¦‚æœæ²¡æœ‰ uploaded_sdf_name, ä½†ç”¨æˆ·ç»™äº†è‡ªå®šä¹‰æ–‡ä»¶å, åˆ™ç”¨ "ç”¨æˆ·è‡ªå®šä¹‰æ–‡ä»¶å + '.sdf'"
        """
        if not mol:
            return

        # 2D å¯è§†åŒ–
        st.subheader("2D åˆ†å­ç»“æ„")
        st.image(Draw.MolToImage(mol, size=(300, 300)), use_container_width=False)

        # ç”Ÿæˆ 3D æ„è±¡å¹¶èƒ½é‡ä¼˜åŒ–
        mol_3d = Chem.AddHs(mol)
        AllChem.EmbedMolecule(mol_3d, AllChem.ETKDG())
        AllChem.MMFFOptimizeMolecule(mol_3d)

        # 3D å¯è§†åŒ–
        st.subheader("3D åˆ†å­ç»“æ„")
        mol_block = Chem.MolToMolBlock(mol_3d)
        xyzview = py3Dmol.view(width=500, height=400)
        xyzview.addModel(mol_block, "mol")
        xyzview.setStyle({'stick': {}})
        xyzview.zoomTo()
        showmol(xyzview, height=400, width=500)

        # æä¾›ä¿å­˜æŒ‰é’®,å°† 3D ç»“æ„å†™å‡ºä¸º SDF æ–‡ä»¶
        if st.button("ä¿å­˜ 3D ç»“æ„ä¸º SDF"):
            os.makedirs("./result/Prepare_Ligand", exist_ok=True)

            if uploaded_sdf_name:
                # å¦‚æœç”¨æˆ·ä¸Šä¼ äº† SDF,å°±ä½¿ç”¨è¯¥ SDF åï¼ˆå» .sdfï¼‰å¹¶åŠ ä¸Š _prepared
                base_name = os.path.splitext(uploaded_sdf_name)[0]
                out_filename = base_name + "_prepared.sdf"
            else:
                # å¦‚æœæ²¡æœ‰ä¸Šä¼ çš„ SDF,å°±ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„æ–‡ä»¶åï¼ˆä¸å« .sdf åç¼€ï¼‰,å†åŠ ä¸Š .sdf
                if user_defined_filename:
                    out_filename = user_defined_filename.strip() + ".sdf"
                else:
                    # å¦‚æœç”¨æˆ·ä¹Ÿæ²¡æœ‰è¾“å…¥ä»»ä½•è‡ªå®šä¹‰æ–‡ä»¶å,å¯ç»™ä¸€ä¸ªé»˜è®¤å€¼
                    out_filename = "ligand_3d.sdf"

            sdf_path = os.path.join("./result/Prepare_Ligand", out_filename)
            writer = Chem.SDWriter(sdf_path)
            writer.write(mol_3d)
            writer.close()
            st.success(f"å·²å°† 3D ç»“æ„ä¿å­˜åˆ° {sdf_path}")

    # é¦–å…ˆè§£æç”¨æˆ·ä¸Šä¼ çš„ SDF
    mol_from_sdf = None
    uploaded_sdf_name = None

    if sdf_file is not None:
        uploaded_sdf_name = sdf_file.name  # è®°å½•ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å
        try:
            sdf_supplier = Chem.ForwardSDMolSupplier(sdf_file)
            mols = [m for m in sdf_supplier if m is not None]
            if len(mols) > 0:
                mol_from_sdf = mols[0]
            else:
                st.error("æ— æ³•ä» SDF æ–‡ä»¶ä¸­è§£æå‡ºåˆ†å­,è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–å†…å®¹")
        except Exception as e:
            st.error(f"è¯»å– SDF æ–‡ä»¶å‡ºç°é”™è¯¯: {e}")

    if mol_from_sdf:
        # å¦‚æœæˆåŠŸè§£æå‡ºä¸Šä¼ çš„ SDF,åˆ™å±•ç¤ºå¹¶ä¿å­˜
        process_and_show_mol(mol_from_sdf, uploaded_sdf_name=uploaded_sdf_name)
    else:
        # å¦‚æœç”¨æˆ·æ²¡æœ‰ä¸Šä¼  SDF æˆ–ä¸Šä¼ çš„ SDF è§£æå¤±è´¥,åˆ™æŸ¥çœ‹ Ketcher ä¸­æœ‰æ²¡æœ‰è¾“å…¥ SMILES
        if smiles_input:
            mol_from_smiles = Chem.MolFromSmiles(smiles_input)
            if mol_from_smiles:
                user_defined_filename = st.text_input("è¯·è¾“å…¥ä¿å­˜æ—¶çš„ SDF æ–‡ä»¶å (ä¸å«`.sdf`): ", value="my_mol")
                process_and_show_mol(
                    mol_from_smiles, 
                    uploaded_sdf_name=None, 
                    user_defined_filename=user_defined_filename
                )
            else:
                st.error("SMILES æ— æ•ˆ,è¯·é‡æ–°è¾“å…¥æˆ–ç¡®è®¤æ ¼å¼")

# ------------------------------------------------------------------------------
# å£è¢‹é¢„æµ‹
# ------------------------------------------------------------------------------
elif page == "å£è¢‹é¢„æµ‹":
    st.title("å£è¢‹é¢„æµ‹")

    # è®©ç”¨æˆ·é€‰æ‹©å¦‚ä½•åŠ è½½è›‹ç™½è´¨
    option = st.radio("Select how to load the protein:", ("ä¸Šä¼ è›‹ç™½è´¨", "åŠ è½½ç¤ºä¾‹æ–‡ä»¶"))

    # ç”¨äºä¿å­˜ç”¨æˆ·ä¸Šä¼ çš„è›‹ç™½æ–‡ä»¶åç§°ï¼ˆç”¨äºæ›¿æ¢ Pocket Nameï¼‰
    uploaded_pdb_filename = None

    if option == "ä¸Šä¼ è›‹ç™½è´¨":
        try:
            # ç”¨æˆ·ä¸Šä¼ è›‹ç™½è´¨ï¼ˆåªå‡ºç°ä¸€æ¬¡,ä¸ä¼šå†å¼¹äºŒæ¬¡ä¸Šä¼ ï¼‰
            pdb_file = st.file_uploader("è¯·ä¸Šä¼ è›‹ç™½è´¨æ–‡ä»¶ (.pdb)", type=["pdb"])
            
            if pdb_file is not None:
                # è®°ä¸‹ä¸Šä¼ çš„åç§°
                uploaded_pdb_filename = pdb_file.name

                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶çš„æ–¹å¼è¿›è¡Œå£è¢‹é¢„æµ‹
                with tempfile.NamedTemporaryFile(suffix=".pdb", delete=False) as tmp:
                    tmp.write(pdb_file.getvalue())
                    tmp.flush()
                    file_path = tmp.name

                # è°ƒç”¨ p2rank (æˆ–å…¶ä»–å‡½æ•°) ,è¯»å–è¯¥ä¸´æ—¶æ–‡ä»¶è¿›è¡Œé¢„æµ‹
                selected = select_pocket_from_local_protein(
                    file_path,
                    p2rank_home='./utils/p2rank_2.5.1/'
                )
                # é¢„æµ‹å®Œæˆååˆ é™¤è¯¥ä¸´æ—¶æ–‡ä»¶
                os.remove(file_path)

                if selected:
                    pocket = selected
                    st.write("é¢„æµ‹åˆ°çš„å£è¢‹ä¿¡æ¯: ", pocket)

                    # å¦‚æœ rank=1 çš„å£è¢‹
                    if pocket['rank'] == '1':
                        # å¦‚æœä¸Šä¼ äº†æ–‡ä»¶å,åˆ™ç”¨ä¹‹,å¦åˆ™ç”¨ pocket['name']
                        final_name = uploaded_pdb_filename if uploaded_pdb_filename else pocket['name']
                        data = {
                            'Pocket Name': [final_name],
                            'Center': [pocket['center']],
                        }
                        df = pd.DataFrame(data)

                        st.write("æœ€ä¼˜å£è¢‹ä¿¡æ¯é¢„è§ˆ: ")
                        st.dataframe(df)

                        # ç”¨æˆ·ç‚¹å‡»æŒ‰é’®å,æ‰å°†CSVä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                        if st.button("ä¿å­˜ best_pocket.csv"):
                            os.makedirs("./result/Predict_Pocket", exist_ok=True)
                            csv_path = "./result/Predict_Pocket/best_pocket.csv"
                            df.to_csv(csv_path, index=False)
                            st.success(f"best_pocket.csv å·²ä¿å­˜åˆ° {csv_path}")

        except Exception as e:
            st.warning(f"å¤„ç†ä¸Šä¼ è›‹ç™½æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    elif option == "åŠ è½½ç¤ºä¾‹æ–‡ä»¶":
        try:
            # ç”¨ç¤ºä¾‹æ–‡ä»¶å
            uploaded_pdb_filename = "protein_example.pdb"
            # è°ƒç”¨ p2rank åšé¢„æµ‹
            selected = select_pocket_from_local_protein(
                "examples/pocket/protein.pdb", 
                p2rank_home='./utils/p2rank_2.5.1/'
            )
            if selected:
                pocket = selected
                st.write("é¢„æµ‹åˆ°çš„å£è¢‹ä¿¡æ¯: ", pocket)

                if pocket['rank'] == '1':
                    data = {
                        'Pocket Name': [uploaded_pdb_filename],
                        'Center': [pocket['center']],
                    }
                    df = pd.DataFrame(data)

                    st.write("æœ€ä¼˜å£è¢‹ä¿¡æ¯é¢„è§ˆ: ")
                    st.dataframe(df)

                    if st.button("ä¿å­˜ best_pocket.csv"):
                        os.makedirs("./result/Predict_Pocket", exist_ok=True)
                        csv_path = "./result/Predict_Pocket/best_pocket.csv"
                        df.to_csv(csv_path, index=False)
                        st.success(f"best_pocket.csv å·²ä¿å­˜åˆ° {csv_path}")
                        
        except Exception as e:
            st.warning(f"åŠ è½½ç¤ºä¾‹æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# ------------------------------------------------------------------------------
# åˆ†å­å¯¹æ¥
# ------------------------------------------------------------------------------
elif page == "åˆ†å­å¯¹æ¥":
    import tempfile
    import os
    # import shutil

    st.title("åˆ†å­å¯¹æ¥")
    st.write("è¯·ä¸Šä¼ è›‹ç™½è´¨ (PDB æ ¼å¼) å’Œé…ä½“ (SDF æ ¼å¼),å¹¶è®¾ç½®å¯¹æ¥å‚æ•°")

    # è®©ç”¨æˆ·ä¸Šä¼ è›‹ç™½è´¨å’Œé…ä½“æ–‡ä»¶
    protein_file = st.file_uploader("ä¸Šä¼ è›‹ç™½è´¨æ–‡ä»¶ (.pdb)", type=["pdb"])
    ligand_file = st.file_uploader("ä¸Šä¼ é…ä½“æ–‡ä»¶ (.sdf)", type=["sdf"])

    # è®©ç”¨æˆ·ä¸Šä¼ å£è¢‹é¢„æµ‹ç»“æœæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    st.write("å¯é€‰ï¼šä¸Šä¼ å£è¢‹é¢„æµ‹ç»“æœ CSV æ–‡ä»¶,å°†è‡ªåŠ¨å¡«å……å¯¹æ¥ç½‘æ ¼å‚æ•°")
    pocket_csv_file = st.file_uploader("ä¸Šä¼ å£è¢‹é¢„æµ‹ç»“æœæ–‡ä»¶ (CSV)", type=["csv"])

    # åˆå§‹åŒ– session_state ä¸­çš„ç½‘æ ¼å‚æ•°ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'docking_center_x' not in st.session_state:
        st.session_state.docking_center_x = None
    if 'docking_center_y' not in st.session_state:
        st.session_state.docking_center_y = None
    if 'docking_center_z' not in st.session_state:
        st.session_state.docking_center_z = None
    if 'auto_calculated' not in st.session_state:
        st.session_state.auto_calculated = False
    if 'last_protein_name' not in st.session_state:
        st.session_state.last_protein_name = None

    # æ£€æµ‹è›‹ç™½è´¨æ–‡ä»¶æ˜¯å¦æ”¹å˜
    current_protein_name = protein_file.name if protein_file is not None else None
    protein_changed = (current_protein_name != st.session_state.last_protein_name)
    
    if protein_changed and protein_file is not None:
        st.session_state.last_protein_name = current_protein_name
        # è›‹ç™½è´¨æ–‡ä»¶æ”¹å˜äº†ï¼Œé‡ç½®åæ ‡ï¼ˆå¦‚æœæ²¡æœ‰å£è¢‹é¢„æµ‹ï¼‰
        if pocket_csv_file is None:
            st.session_state.docking_center_x = None
            st.session_state.docking_center_y = None
            st.session_state.docking_center_z = None

    # é»˜è®¤ç½‘æ ¼å‚æ•°
    center_x = st.session_state.docking_center_x
    center_y = st.session_state.docking_center_y
    center_z = st.session_state.docking_center_z

    # å¦‚æœä¸Šä¼ äº†å£è¢‹é¢„æµ‹ç»“æœï¼Œä¼˜å…ˆä½¿ç”¨
    if pocket_csv_file is not None:
        try:
            # è¯»å– CSV æ–‡ä»¶å¹¶è·å–ä¸­å¿ƒåæ ‡
            pocket_df = pd.read_csv(pocket_csv_file)
            if "Center" in pocket_df.columns:
                center_coords = pocket_df.loc[0, "Center"]  # è·å–ç¬¬ä¸€ä¸ªå£è¢‹çš„ä¸­å¿ƒåæ ‡
                if isinstance(center_coords, str):
                    coords = [float(c) for c in re.findall(r"[-+]?[0-9]*\.?[0-9]+", center_coords)]
                    if len(coords) == 3:
                        center_x, center_y, center_z = coords
                        st.session_state.docking_center_x = center_x
                        st.session_state.docking_center_y = center_y
                        st.session_state.docking_center_z = center_z
                        st.session_state.auto_calculated = False
                        st.success(f"âœ… å·²ä» CSV æ–‡ä»¶è¯»å–å£è¢‹ä¸­å¿ƒ: ({center_x:.2f}, {center_y:.2f}, {center_z:.2f})")
                    else:
                        st.warning("CSV æ–‡ä»¶ä¸­çš„ Center æ ¼å¼ä¸æ­£ç¡®,æ— æ³•è‡ªåŠ¨å¡«å……ç½‘æ ¼å‚æ•°")
                else:
                    st.warning("CSV æ–‡ä»¶ä¸­çš„ Center æ ¼å¼ä¸æ­£ç¡®,æ— æ³•è‡ªåŠ¨å¡«å……ç½‘æ ¼å‚æ•°")
            else:
                st.warning("CSV æ–‡ä»¶ä¸­æœªæ‰¾åˆ° Center åˆ—,æ— æ³•è‡ªåŠ¨å¡«å……ç½‘æ ¼å‚æ•°")
        except Exception as e:
            st.error(f"è¯»å– CSV æ–‡ä»¶æ—¶å‡ºç°é”™è¯¯: {e}")
    
    # å¦‚æœç”¨æˆ·ä¸Šä¼ äº†è›‹ç™½è´¨ä½†æ²¡æœ‰å£è¢‹é¢„æµ‹ç»“æœï¼Œè‡ªåŠ¨è®¡ç®—è›‹ç™½è´¨è´¨å¿ƒ
    elif protein_file is not None and center_x is None:
        try:
            from biopandas.pdb import PandasPdb
            import io
            
            # è¯»å–è›‹ç™½è´¨æ–‡ä»¶å¹¶è®¡ç®—è´¨å¿ƒ
            pdb_content = io.BytesIO(protein_file.getvalue())
            pmol = PandasPdb().read_pdb(pdb_content)
            pdf = pmol.df['ATOM']
            
            if len(pdf) == 0:
                raise ValueError("PDB æ–‡ä»¶ä¸­æ²¡æœ‰ ATOM è®°å½•")
            
            center_x = float(pdf['x_coord'].mean())
            center_y = float(pdf['y_coord'].mean())
            center_z = float(pdf['z_coord'].mean())
            
            # ä¿å­˜åˆ° session_state
            st.session_state.docking_center_x = center_x
            st.session_state.docking_center_y = center_y
            st.session_state.docking_center_z = center_z
            st.session_state.auto_calculated = True
            
            st.info(f"âœ… å·²è‡ªåŠ¨è®¡ç®—è›‹ç™½è´¨è´¨å¿ƒä½œä¸ºå¯¹æ¥ç½‘æ ¼ä¸­å¿ƒ: ({center_x:.2f}, {center_y:.2f}, {center_z:.2f})")
            st.warning("âš ï¸ å»ºè®®å…ˆè¿›è¡Œ'å£è¢‹é¢„æµ‹'ä»¥è·å¾—æ›´å‡†ç¡®çš„å¯¹æ¥ä½ç‚¹ï¼")
        except Exception as e:
            st.error(f"âŒ æ— æ³•è‡ªåŠ¨è®¡ç®—è›‹ç™½è´¨è´¨å¿ƒ: {e}")
            st.warning("è¯·æ‰‹åŠ¨è¾“å…¥å¯¹æ¥ç½‘æ ¼å‚æ•°æˆ–å…ˆè¿›è¡Œå£è¢‹é¢„æµ‹")
            center_x = 0.0
            center_y = 0.0
            center_z = 0.0
            st.session_state.docking_center_x = center_x
            st.session_state.docking_center_y = center_y
            st.session_state.docking_center_z = center_z
    
    # è®¾ç½®é»˜è®¤å€¼ï¼ˆå¦‚æœä»ç„¶ä¸º Noneï¼‰
    if center_x is None:
        center_x = 0.0
        center_y = 0.0
        center_z = 0.0
        st.session_state.docking_center_x = center_x
        st.session_state.docking_center_y = center_y
        st.session_state.docking_center_z = center_z

    # æ˜¾ç¤ºç½‘æ ¼å‚æ•°è¾“å…¥æ¡†,æ— è®ºæ˜¯å¦ä¸Šä¼  CSV æ–‡ä»¶
    st.subheader("è®¾ç½®å¯¹æ¥å£è¢‹å‚æ•°")
    
    # æ·»åŠ ä¸€ä¸ª"é‡ç½®ä¸ºè´¨å¿ƒ"æŒ‰é’®
    col1, col2 = st.columns([3, 1])
    with col2:
        if protein_file is not None:
            if st.button("ğŸ”„ é‡æ–°è®¡ç®—è´¨å¿ƒ"):
                try:
                    from biopandas.pdb import PandasPdb
                    import io
                    
                    pdb_content = io.BytesIO(protein_file.getvalue())
                    pmol = PandasPdb().read_pdb(pdb_content)
                    pdf = pmol.df['ATOM']
                    
                    center_x = float(pdf['x_coord'].mean())
                    center_y = float(pdf['y_coord'].mean())
                    center_z = float(pdf['z_coord'].mean())
                    
                    st.session_state.docking_center_x = center_x
                    st.session_state.docking_center_y = center_y
                    st.session_state.docking_center_z = center_z
                    st.session_state.auto_calculated = True
                    
                    st.success(f"âœ… å·²é‡æ–°è®¡ç®—: ({center_x:.2f}, {center_y:.2f}, {center_z:.2f})")
                except Exception as e:
                    st.error(f"è®¡ç®—å¤±è´¥: {e}")
    
    center_x = st.number_input("Center X", value=float(center_x), format="%.2f", key="input_center_x")
    center_y = st.number_input("Center Y", value=float(center_y), format="%.2f", key="input_center_y")
    center_z = st.number_input("Center Z", value=float(center_z), format="%.2f", key="input_center_z")

    size_x = st.number_input("Size X", value=100.0)
    size_y = st.number_input("Size Y", value=100.0)
    size_z = st.number_input("Size Z", value=100.0)

    # å½“ç”¨æˆ·ç‚¹å‡»"å¼€å§‹åˆ†å­å¯¹æ¥"æ—¶,ç”Ÿæˆ docking_grid.json æ–‡ä»¶å¹¶è°ƒç”¨å¯¹æ¥å‘½ä»¤
    if st.button("å¼€å§‹åˆ†å­å¯¹æ¥"):
        # å¦‚æœæ²¡æœ‰ä¸Šä¼ è›‹ç™½è´¨æˆ–é…ä½“,æç¤ºé”™è¯¯
        if not protein_file or not ligand_file:
            st.error("è¯·å…ˆä¸Šä¼ è›‹ç™½è´¨ (pdb) å’Œé…ä½“ (sdf) æ–‡ä»¶")
        else:
            # éªŒè¯å¯¹æ¥ç½‘æ ¼å‚æ•°
            if center_x == 0.0 and center_y == 0.0 and center_z == 0.0:
                st.error("âš ï¸ è­¦å‘Šï¼šå¯¹æ¥ç½‘æ ¼ä¸­å¿ƒä¸º (0, 0, 0)ï¼")
                st.warning("""
                è¿™å¯èƒ½å¯¼è‡´å¯¹æ¥å¤±è´¥ã€‚è¯·ï¼š
                1. ç‚¹å‡»ä¸Šæ–¹çš„ ğŸ”„ "é‡æ–°è®¡ç®—è´¨å¿ƒ" æŒ‰é’®
                2. æˆ–å…ˆè¿›è¡Œ"å£è¢‹é¢„æµ‹"ä»¥è·å¾—å‡†ç¡®çš„å¯¹æ¥ä½ç‚¹
                3. æˆ–æ‰‹åŠ¨è¾“å…¥æ­£ç¡®çš„å¯¹æ¥ç½‘æ ¼ä¸­å¿ƒåæ ‡
                """)
            else:
                st.info(f"ğŸ“ å¯¹æ¥ç½‘æ ¼ä¸­å¿ƒ: ({center_x:.2f}, {center_y:.2f}, {center_z:.2f})")
            
            try:
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹ä¿å­˜ç¼“å­˜æ–‡ä»¶
                with tempfile.TemporaryDirectory() as temp_dir:
                    docking_grid = {
                        "center_x": center_x,
                        "center_y": center_y,
                        "center_z": center_z,
                        "size_x": size_x,
                        "size_y": size_y,
                        "size_z": size_z
                    }
                    
                    # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å° docking_grid
                    st.write("è°ƒè¯•ä¿¡æ¯ - å¯¹æ¥ç½‘æ ¼å‚æ•°ï¼š", docking_grid)
                    docking_grid_path = os.path.join(temp_dir, "docking_grid.json")

                    with open(docking_grid_path, "w") as f:
                        json.dump(docking_grid, f, indent=4)

                    # ä¿å­˜è›‹ç™½è´¨å’Œé…ä½“æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    protein_path = os.path.join(temp_dir, "protein.pdb")
                    ligand_path = os.path.join(temp_dir, "ligand.sdf")

                    with open(protein_path, "wb") as f:
                        f.write(protein_file.getvalue())

                    with open(ligand_path, "wb") as f:
                        f.write(ligand_file.getvalue())

                    # è®¾ç½®ç»“æœä¿å­˜ç›®å½•
                    result_dir = "./result/Docking_Result"
                    os.makedirs(result_dir, exist_ok=True)

                    # æ„é€ å‘½ä»¤
                    command = (
                        f"conda run -n flashdock python ./models/Uni-Mol/unimol_docking_v2/interface/demo.py "
                        f"--mode single "
                        f"--conf-size 10 "
                        f"--cluster "
                        f"--input-protein {protein_path} "
                        f"--input-ligand {ligand_path} "
                        f"--input-docking-grid {docking_grid_path} "
                        f"--output-ligand-name ligand_predict "
                        f"--output-ligand-dir {result_dir} "
                        f"--steric-clash-fix "
                        f"--model-dir ./models/Uni-Mol/unimol_docking_v2/unimol_docking_v2_240517.pt"
                    )

                    # æ‰§è¡Œå‘½ä»¤
                    result = subprocess.run(command, shell=True, capture_output=True, text=True)

                    # æ ¹æ®å‘½ä»¤è¿”å›å€¼åˆ¤æ–­æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
                    if result.returncode == 0:
                        st.success("åˆ†å­å¯¹æ¥å®Œæˆ!")
                        st.text_area("å¯¹æ¥è¾“å‡ºæ—¥å¿—", value=result.stdout, height=150)

                        # åˆ†å­å¯¹æ¥å®Œæˆå,å¤„ç†ç»“æœæ–‡ä»¶
                        try:
                            ligand_output_path = os.path.join(result_dir, "ligand_predict.sdf")

                            # åˆ é™¤ç»“æœç›®å½•ä¸­é™¤ ligand_predict.sdf å¤–çš„æ‰€æœ‰æ–‡ä»¶
                            for file_name in os.listdir(result_dir):
                                file_path = os.path.join(result_dir, file_name)
                                if file_name != "ligand_predict.sdf" and os.path.isfile(file_path):
                                    os.remove(file_path)

                            # é‡å‘½å ligand_predict.sdf
                            output_name = f"{os.path.splitext(ligand_file.name)[0]}_{os.path.splitext(protein_file.name)[0]}_docked.sdf"
                            renamed_path = os.path.join(result_dir, output_name)
                            os.rename(ligand_output_path, renamed_path)

                            # æç¤ºç”¨æˆ·ç»“æœä¿å­˜ä½ç½®
                            st.success(f"å¯¹æ¥ç»“æœä¿å­˜ä¸º {renamed_path}")

                            # å¯è§†åŒ–å¯¹æ¥ç»“æœ
                            st_molstar_docking(
                                protein_path, 
                                renamed_path, 
                                key="5", 
                                height=600
                            )
                        except Exception as e:
                            st.error(f"å¤„ç†ç»“æœæ–‡ä»¶æ—¶å‡ºé”™: {e}")

                    else:
                        st.error("åˆ†å­å¯¹æ¥å¤±è´¥ï¼")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯ pocket ä¸ºç©ºçš„é”™è¯¯
                        if "No protein atoms found in the docking grid box" in result.stderr or "Mean of empty slice" in result.stderr:
                            st.error("âŒ åœ¨æŒ‡å®šçš„å¯¹æ¥ç½‘æ ¼èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°è›‹ç™½è´¨åŸå­ï¼")
                            st.warning("ğŸ’¡ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")
                            st.markdown("""
                            1. **å»ºè®®**ï¼šå…ˆè¿›è¡Œ"å£è¢‹é¢„æµ‹"ä»¥è·å¾—å‡†ç¡®çš„å¯¹æ¥ä½ç‚¹
                            2. æ£€æŸ¥å¯¹æ¥ç½‘æ ¼çš„ä¸­å¿ƒåæ ‡æ˜¯å¦æ­£ç¡®
                            3. å¢å¤§å¯¹æ¥ç½‘æ ¼çš„å°ºå¯¸ï¼ˆSize X/Y/Zï¼‰
                            4. ç¡®è®¤ä¸Šä¼ çš„è›‹ç™½è´¨æ–‡ä»¶æ ¼å¼æ­£ç¡®
                            """)
                        
                        st.text_area("é”™è¯¯ä¿¡æ¯", value=result.stderr, height=150)

            except Exception as e:
                st.error(f"å¯¹æ¥è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
                st.warning("ğŸ’¡ æç¤ºï¼šå»ºè®®å…ˆè¿›è¡Œ'å£è¢‹é¢„æµ‹'ä»¥è·å¾—å‡†ç¡®çš„å¯¹æ¥ä½ç‚¹ï¼")

# ------------------------------------------------------------------------------
# æ‰¹é‡å£è¢‹é¢„æµ‹ä¸å¯¹æ¥
# ------------------------------------------------------------------------------
elif page == "æ‰¹é‡å£è¢‹é¢„æµ‹ä¸å¯¹æ¥":
    import os
    import pandas as pd
    import subprocess
    import tempfile
    import json
    from pathlib import Path
    import streamlit as st
    from streamlit_molstar.pocket import select_pocket_from_local_protein

    st.title("æ‰¹é‡å£è¢‹é¢„æµ‹ä¸åˆ†å­å¯¹æ¥")

    # å®šä¹‰å›ºå®šè·¯å¾„
    batch_docking_dir = Path("./batch_docking/input")
    result_dir = Path("./batch_docking/input")
    result_dir.mkdir(parents=True, exist_ok=True)

    # æ£€æŸ¥ Batch_Docking ç›®å½•æ˜¯å¦å­˜åœ¨
    if not batch_docking_dir.exists():
        st.error(f"ç›®å½• {batch_docking_dir} ä¸å­˜åœ¨è¯·åˆ›å»ºè¯¥ç›®å½•å¹¶æ·»åŠ  PDB å’Œ SDF æ–‡ä»¶")
    else:
        # è‡ªåŠ¨ç”Ÿæˆä»»åŠ¡ CSV æ–‡ä»¶
        def generate_task_csv():
            pdb_files = list(batch_docking_dir.glob("*.pdb"))
            sdf_files = list(batch_docking_dir.glob("*.sdf"))

            if not pdb_files:
                st.error("åœ¨ ./batch_docking/input æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ° PDB æ–‡ä»¶è¯·æ·»åŠ è‡³å°‘ä¸€ä¸ª PDB æ–‡ä»¶")
                return None
            if not sdf_files:
                st.error("åœ¨ ./batch_docking/input æ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ° SDF æ–‡ä»¶è¯·æ·»åŠ è‡³å°‘ä¸€ä¸ª SDF æ–‡ä»¶")
                return None

            tasks = []
            for pdb_file in pdb_files:
                for sdf_file in sdf_files:
                    tasks.append({
                        "Protein": pdb_file.name,
                        "Ligand": sdf_file.name,
                        "Run": "Yes"  # é»˜è®¤æ‰€æœ‰ä»»åŠ¡ä¸º "Yes"
                    })

            task_df = pd.DataFrame(tasks)
            return task_df

        # ç”Ÿæˆä»»åŠ¡ DataFrame
        task_df = generate_task_csv()

        if task_df is not None:
            # æä¾›ä¸‹è½½ä»»åŠ¡ CSV çš„æŒ‰é’®
            csv = task_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ä¸‹è½½ä»»åŠ¡ CSV æ–‡ä»¶",
                data=csv,
                file_name="docking_tasks.csv",
                mime="text/csv"
            )

            st.markdown("---")
            st.info("""
                1. ä¸‹è½½ä¸Šæ–¹çš„ä»»åŠ¡ CSV æ–‡ä»¶
                2. åœ¨æœ¬åœ°ç¼–è¾‘ CSV æ–‡ä»¶,ä¿®æ”¹ `Run` åˆ—ä¸º `Yes` çš„ä»»åŠ¡å°†è¢«æ‰§è¡Œ,`No` åˆ—çš„ä»»åŠ¡å°†è¢«è·³è¿‡
                3. ä¿®æ”¹å®Œæˆå,ä¸Šä¼ ä¿®æ”¹åçš„ CSV æ–‡ä»¶å¹¶ç‚¹å‡»â€œå¼€å§‹æ‰¹é‡é¢„æµ‹å’Œå¯¹æ¥â€æŒ‰é’®
            """)

            # ä¸Šä¼ ä¿®æ”¹åçš„ä»»åŠ¡ CSV æ–‡ä»¶
            uploaded_csv = st.file_uploader("ä¸Šä¼ ä¿®æ”¹åçš„ä»»åŠ¡ CSV æ–‡ä»¶", type=["csv"], key="upload_task_csv")

            if uploaded_csv is not None:
                try:
                    uploaded_tasks_df = pd.read_csv(uploaded_csv)

                    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
                    required_columns = {"Protein", "Ligand", "Run"}
                    if not required_columns.issubset(uploaded_tasks_df.columns):
                        st.error(f"ä¸Šä¼ çš„ä»»åŠ¡æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—ï¼š{required_columns - set(uploaded_tasks_df.columns)}")
                    else:
                        # è¿‡æ»¤éœ€è¦è¿è¡Œçš„ä»»åŠ¡
                        tasks_to_run = uploaded_tasks_df[uploaded_tasks_df["Run"].str.lower() == "yes"]

                        if tasks_to_run.empty:
                            st.warning("æ²¡æœ‰ä»»åŠ¡éœ€è¦è¿è¡Œ,è¯·ç¡®ä¿è‡³å°‘æœ‰ä¸€é¡¹ä»»åŠ¡çš„ `Run` åˆ—ä¸º `Yes`")
                        else:
                            st.write(f"å‘ç° {len(tasks_to_run)} ä¸ªä»»åŠ¡éœ€è¦è¿è¡Œ")

                            # æ˜¾ç¤ºéœ€è¦è¿è¡Œçš„ä»»åŠ¡è¡¨æ ¼
                            st.subheader("å¾…è¿è¡Œçš„ä»»åŠ¡åˆ—è¡¨")
                            st.dataframe(tasks_to_run[['Protein', 'Ligand']].reset_index(drop=True))

                            # å¼€å§‹æ‰¹é‡é¢„æµ‹å’Œå¯¹æ¥æŒ‰é’®
                            if st.button("å¼€å§‹æ‰¹é‡é¢„æµ‹å’Œå¯¹æ¥", key="start_batch_processing"):
                                log_messages = []
                                progress_bar = st.progress(0)
                                status_text = st.empty()

                                for i, task in tasks_to_run.iterrows():
                                    protein_path = batch_docking_dir / task["Protein"]
                                    ligand_path = batch_docking_dir / task["Ligand"]

                                    # å£è¢‹é¢„æµ‹å‰æ›´æ–°çŠ¶æ€
                                    status_text.text(f"ä»»åŠ¡ {i + 1}/{len(tasks_to_run)}: æ­£åœ¨ä¸º {task['Protein']} é¢„æµ‹å£è¢‹...")

                                    # å£è¢‹é¢„æµ‹
                                    try:
                                        # ä¸ºæ¯ä¸ªä»»åŠ¡ä¼ é€’å”¯ä¸€çš„ key
                                        pocket_result = select_pocket_from_local_protein(
                                            str(protein_path), 
                                            p2rank_home='./others/p2rank_2.5.1/',
                                            key=f"select_pocket_{i}"  # æ·»åŠ å”¯ä¸€ key
                                        )
                                    except Exception as e:
                                        log_messages.append(f"ä»»åŠ¡ {task['Protein']} å’Œ {task['Ligand']} å£è¢‹é¢„æµ‹å¤±è´¥ï¼š{e}")
                                        progress_bar.progress((i + 1) / len(tasks_to_run))
                                        continue

                                    if pocket_result:
                                        center_coords = [float(coord) for coord in pocket_result["center"]]
                                        docking_grid = {
                                            "center_x": center_coords[0],
                                            "center_y": center_coords[1],
                                            "center_z": center_coords[2],
                                            "size_x": 100.0,
                                            "size_y": 100.0,
                                            "size_z": 100.0,
                                        }

                                        # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜å‚¨å¯¹æ¥ç½‘æ ¼
                                        with tempfile.TemporaryDirectory() as temp_dir:
                                            docking_grid_path = Path(temp_dir) / "docking_grid.json"
                                            with open(docking_grid_path, "w") as f:
                                                json.dump(docking_grid, f, indent=4)

                                            # æ›´æ–°çŠ¶æ€ï¼šå¼€å§‹å¯¹æ¥
                                            status_text.text(f"ä»»åŠ¡ {i + 1}/{len(tasks_to_run)}: æ­£åœ¨å¯¹æ¥ {task['Protein']} å’Œ {task['Ligand']}...")

                                            # æ„é€ å¯¹æ¥å‘½ä»¤
                                            command = (
                                                f"conda run -n flashdock python ./models/Uni-Mol/unimol_docking_v2/interface/demo.py "
                                                f"--mode single "
                                                f"--conf-size 10 "
                                                f"--cluster "
                                                f"--input-protein {protein_path} "
                                                f"--input-ligand {ligand_path} "
                                                f"--input-docking-grid {docking_grid_path} "
                                                f"--output-ligand-name ligand_predict "
                                                f"--output-ligand-dir {result_dir} "
                                                f"--steric-clash-fix "
                                                f"--model-dir ./models/Uni-Mol/unimol_docking_v2/unimol_docking_v2_240517.pt"
                                            )

                                            # æ‰§è¡Œå¯¹æ¥å‘½ä»¤
                                            result = subprocess.run(command, shell=True, capture_output=True, text=True)

                                            if result.returncode == 0:
                                                ligand_output_path = result_dir / "ligand_predict.sdf"
                                                output_name = f"{protein_path.stem}_{ligand_path.stem}_docked.sdf"
                                                renamed_path = result_dir / output_name

                                                try:
                                                    os.rename(ligand_output_path, renamed_path)
                                                    log_messages.append(f"ä»»åŠ¡ {task['Protein']} å’Œ {task['Ligand']} å¯¹æ¥å®Œæˆç»“æœä¿å­˜ä¸º {renamed_path}")
                                                except Exception as e:
                                                    log_messages.append(f"ä»»åŠ¡ {task['Protein']} å’Œ {task['Ligand']} ç»“æœä¿å­˜å¤±è´¥ï¼š{e}")
                                            else:
                                                log_messages.append(f"ä»»åŠ¡ {task['Protein']} å’Œ {task['Ligand']} å¯¹æ¥å¤±è´¥é”™è¯¯ä¿¡æ¯ï¼š{result.stderr}")

                                    else:
                                        log_messages.append(f"ä»»åŠ¡ {task['Protein']} çš„å£è¢‹ä¿¡æ¯æœªæ‰¾åˆ°")

                                    # æ›´æ–°è¿›åº¦æ¡
                                    progress_bar.progress((i + 1) / len(tasks_to_run))

                                # æ‰€æœ‰ä»»åŠ¡å®Œæˆåæ›´æ–°çŠ¶æ€
                                status_text.text("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")

                                # æ˜¾ç¤ºæ—¥å¿—
                                st.success("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
                                st.text_area("ä»»åŠ¡æ—¥å¿—", value="\n".join(log_messages), height=300)
                except pd.errors.EmptyDataError:
                    st.error("ä¸Šä¼ çš„ CSV æ–‡ä»¶ä¸ºç©º,è¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹")
                except pd.errors.ParserError:
                    st.error("ä¸Šä¼ çš„ CSV æ–‡ä»¶æ ¼å¼é”™è¯¯,è¯·ç¡®ä¿æ–‡ä»¶ä¸ºæœ‰æ•ˆçš„ CSV æ ¼å¼")
                except Exception as e:
                    st.error(f"è¯»å–ä»»åŠ¡æ–‡ä»¶æ—¶å‡ºé”™ï¼š{e}")

# ------------------------------------------------------------------------------
# é¢„æµ‹äº²å’ŒåŠ›
# ------------------------------------------------------------------------------

elif page == "é¢„æµ‹äº²å’ŒåŠ›":
    import os
    import tempfile
    import subprocess
    import pandas as pd
    import streamlit as st
    import time
    import matplotlib.pyplot as plt
    import seaborn as sns

    if page == "é¢„æµ‹äº²å’ŒåŠ›":
        st.title("é¢„æµ‹äº²å’ŒåŠ›")
        st.write("åœ¨æ­¤é¡µé¢,ä½ å¯ä»¥è¿›è¡Œå°åˆ†å­ä¸è›‹ç™½è´¨çš„ç»“åˆäº²å’ŒåŠ›é¢„æµ‹é€‰æ‹©å•ä¸ªé¢„æµ‹æˆ–æ‰¹é‡é¢„æµ‹æ¨¡å¼")

        # æ¨¡å¼é€‰æ‹©
        mode = st.radio("é€‰æ‹©æ¨¡å¼", ("å•ä¸ªé¢„æµ‹", "æ‰¹é‡é¢„æµ‹"))

        if mode == "å•ä¸ªé¢„æµ‹":
            st.subheader("å•ä¸ªè›‹ç™½ä¸å°åˆ†å­çš„äº²å’ŒåŠ›é¢„æµ‹")

            # ç”¨æˆ·ä¸Šä¼ è›‹ç™½è´¨ PDB æ–‡ä»¶
            protein_file = st.file_uploader("ä¸Šä¼ è›‹ç™½è´¨ PDB æ–‡ä»¶", type=["pdb"])

            # ç”¨æˆ·ä¸Šä¼ å°åˆ†å­ SDF æ–‡ä»¶
            ligand_file = st.file_uploader("ä¸Šä¼ å°åˆ†å­ SDF æ–‡ä»¶", type=["sdf"])

            # æŒ‰é’®è§¦å‘é¢„æµ‹
            if st.button("å¼€å§‹é¢„æµ‹"):
                if protein_file is None:
                    st.error("è¯·ä¸Šä¼ è›‹ç™½è´¨ PDB æ–‡ä»¶")
                elif ligand_file is None:
                    st.error("è¯·ä¸Šä¼ å°åˆ†å­ SDF æ–‡ä»¶")
                else:
                    with st.spinner("æ­£åœ¨è¿›è¡Œäº²å’ŒåŠ›é¢„æµ‹,è¯·ç¨å€™..."):
                        try:
                            # åˆ›å»ºä¸´æ—¶ç›®å½•
                            with tempfile.TemporaryDirectory() as tmpdir:
                                # ä¿å­˜ä¸Šä¼ çš„è›‹ç™½è´¨æ–‡ä»¶
                                protein_path = os.path.join(tmpdir, protein_file.name)
                                with open(protein_path, "wb") as f:
                                    f.write(protein_file.getbuffer())

                                # ä¿å­˜ä¸Šä¼ çš„å°åˆ†å­æ–‡ä»¶
                                ligand_path = os.path.join(tmpdir, ligand_file.name)
                                with open(ligand_path, "wb") as f:
                                    f.write(ligand_file.getbuffer())

                                # è¾“å‡º CSV æ–‡ä»¶è·¯å¾„
                                output_csv_path = os.path.join(tmpdir, "single_prediction.csv")

                                # è°ƒç”¨é¢„æµ‹è„šæœ¬
                                pred_dir = "./models/PLANET"
                                pred_script = "pred.py"
                                pred_script_path = os.path.join(pred_dir, pred_script)

                                cmd = [
                                    "conda run -n flashdock python",
                                    pred_script_path,
                                    "-p", protein_path,
                                    "-l", ligand_path,
                                    "-m", ligand_path,
                                    "-o", output_csv_path
                                ]

                                result = subprocess.run(cmd, capture_output=True, text=True)

                                if result.returncode != 0:
                                    st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:\n{result.stderr}")
                                else:
                                    if os.path.exists(output_csv_path):
                                        df = pd.read_csv(output_csv_path)
                                        st.success("é¢„æµ‹å®Œæˆ! ç»“æœå¦‚ä¸‹: ")
                                        st.dataframe(df)
                                    else:
                                        st.error("é¢„æµ‹å®Œæˆä½†æœªæ‰¾åˆ°è¾“å‡º CSV æ–‡ä»¶")
                        except Exception as e:
                            st.error(f"å‘ç”Ÿå¼‚å¸¸: {e}")

        elif mode == "æ‰¹é‡é¢„æµ‹":
            st.subheader("æ‰¹é‡è›‹ç™½ä¸å°åˆ†å­äº²å’ŒåŠ›é¢„æµ‹")

            # æŒ‰é’®è§¦å‘é¢„æµ‹
            if st.button("å¼€å§‹æ‰¹é‡é¢„æµ‹"):
                with st.spinner("æ­£åœ¨è¿›è¡Œæ‰¹é‡äº²å’ŒåŠ›é¢„æµ‹,è¯·ç¨å€™..."):
                    try:
                        batch_dir = "./batch_docking/output"
                        if not os.path.exists(batch_dir):
                            st.error("æ‰¹é‡é¢„æµ‹ç›®å½•ä¸å­˜åœ¨")
                        else:
                            final_results = []

                            # æ‰«ææ–‡ä»¶å¤¹ä¸­çš„ SDF å’Œ PDB æ–‡ä»¶
                            sdf_files = [f for f in os.listdir(batch_dir) if f.endswith(".sdf")]
                            pdb_files = [f for f in os.listdir(batch_dir) if f.endswith(".pdb")]

                            st.write("å‘ç°ä»¥ä¸‹è›‹ç™½è´¨æ–‡ä»¶ï¼š")
                            st.write(pdb_files)
                            st.write("å‘ç°ä»¥ä¸‹é…ä½“æ–‡ä»¶ï¼š")
                            st.write(sdf_files)

                            progress_bar = st.progress(0)
                            total_files = len(sdf_files)

                            for i, sdf_file in enumerate(sdf_files):
                                receptor_name = sdf_file.split("_")[0]
                                ligand_name = sdf_file.split("_")[1]
                                pdb_file = os.path.join(batch_dir, receptor_name + ".pdb")
                                sdf_file_path = os.path.join(batch_dir, sdf_file)

                                if os.path.exists(pdb_file):
                                    st.text(f"æ­£åœ¨è®¡ç®—ç¬¬ {i + 1}/{total_files} å¯¹ï¼šè›‹ç™½ {pdb_file} å’Œ é…ä½“ {sdf_file} çš„äº²å’ŒåŠ›...")
                                    with tempfile.TemporaryDirectory() as tmpdir:
                                        output_csv_path_tmp = os.path.join(tmpdir, "temp_result.csv")

                                        cmd = [
                                            "conda run -n flashdock python",
                                            "./models/PLANET/pred.py",
                                            "-p", pdb_file,
                                            "-l", sdf_file_path,
                                            "-m", sdf_file_path,
                                            "-o", output_csv_path_tmp
                                        ]

                                        result = subprocess.run(cmd, capture_output=True, text=True)

                                        if result.returncode == 0 and os.path.exists(output_csv_path_tmp):
                                            temp_df = pd.read_csv(output_csv_path_tmp)
                                            if "Binding_Affinity" in temp_df.columns:
                                                binding_affinity = temp_df["Binding_Affinity"].iloc[0]
                                                final_results.append({
                                                    "Protein_File": receptor_name,
                                                    "Ligand_File": ligand_name,
                                                    "Binding_Affinity": binding_affinity
                                                })
                                        else:
                                            st.error(f"æ–‡ä»¶ {sdf_file} å¤„ç†å¤±è´¥")

                                # æ›´æ–°è¿›åº¦æ¡
                                progress_bar.progress((i + 1) / total_files)
                                time.sleep(0.1)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´

                            if final_results:
                                results_df = pd.DataFrame(final_results)

                                # ä¿å­˜ç»“æœåˆ° Binding_Affinity æ–‡ä»¶å¤¹
                                binding_affinity_dir = "./Result/Binding_Affinity"
                                os.makedirs(binding_affinity_dir, exist_ok=True)

                                output_csv_path = os.path.join(binding_affinity_dir, "batch_prediction_results.csv")
                                results_df.to_csv(output_csv_path, index=False)

                                st.success("æ‰¹é‡é¢„æµ‹å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°ä»¥ä¸‹ç›®å½•ï¼š")
                                st.write(output_csv_path)

                                # ç»˜åˆ¶çƒ­å›¾
                                st.subheader("äº²å’ŒåŠ›çƒ­å›¾")
                                heatmap_data = results_df.pivot(index="Protein_File", columns="Ligand_File", values="Binding_Affinity")
                                plt.figure(figsize=(10, 8), dpi=600)
                                sns.heatmap(heatmap_data, annot=True, cmap="coolwarm", fmt=".2f")
                                plt.xlabel("Ligands")
                                plt.ylabel("Proteins")
                                plt.title("Binding Affinity Heatmap")
                                st.pyplot(plt)

                                heatmap_path = os.path.join(binding_affinity_dir, "binding_affinity_heatmap.png")
                                plt.savefig(heatmap_path, dpi=600)

                                st.write("çƒ­å›¾å·²ä¿å­˜åˆ°ä»¥ä¸‹ç›®å½•ï¼š")
                                st.write(heatmap_path)

                            else:
                                st.error("æœªç”Ÿæˆä»»ä½•é¢„æµ‹ç»“æœ")
                    except Exception as e:
                        st.error(f"å‘ç”Ÿå¼‚å¸¸: {e}")




# ------------------------------------------------------------------------------
# ä½œè€…ä¿¡æ¯
# ------------------------------------------------------------------------------
